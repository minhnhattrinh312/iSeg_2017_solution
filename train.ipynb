{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":613,"status":"ok","timestamp":1629823603593,"user":{"displayName":"Minh Nhật Trịnh","photoUrl":"","userId":"05773131169689709632"},"user_tz":-420},"id":"Nn-qM3LsJCis","outputId":"62b35f5e-1896-4580-d8b3-81ca320e1bf5"},"outputs":[{"name":"stdout","output_type":"stream","text":["Tue Aug 24 16:46:39 2021       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 470.57.02    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   37C    P0    26W / 250W |      0MiB / 16280MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}],"source":["!nvidia-smi"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":679,"status":"ok","timestamp":1629823607570,"user":{"displayName":"Minh Nhật Trịnh","photoUrl":"","userId":"05773131169689709632"},"user_tz":-420},"id":"Izv8OjTgKfV8","outputId":"525d1c9d-505c-4b9d-e2ed-0a289c25a32f"},"outputs":[{"name":"stdout","output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xs6nunNwJIvB"},"outputs":[],"source":["import zipfile\n","# with zipfile.ZipFile(\"/dataISEG_np/train_patch32_stride8.zip\", 'r') as zip_ref:\n","#     zip_ref.extractall(\"data_train\")\n","with zipfile.ZipFile(\"dataISEG_np/test_patch32_stride8.zip\", 'r') as zip_ref:\n","    zip_ref.extractall(\"data_test\")\n","# with zipfile.ZipFile(\"/dataISEG_np/pseudo_data.zip\", 'r') as zip_ref:\n","#     zip_ref.extractall(\"pseudo_data\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2046,"status":"ok","timestamp":1629823613293,"user":{"displayName":"Minh Nhật Trịnh","photoUrl":"","userId":"05773131169689709632"},"user_tz":-420},"id":"4peVAgmCJXZi","outputId":"855a57df-41ee-4907-beb3-49b3f8991824"},"outputs":[{"name":"stdout","output_type":"stream","text":["/content/drive/MyDrive/iseg2019\n"]}],"source":["%cd /content/drive/MyDrive/\n","%run U_Unet.ipynb"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GmHc63BbJY-E"},"outputs":[],"source":["# !pip install import-ipynb\n","# import import_ipynb\n","# !pip install volumentations-3D\n","# from volumentations import *\n","# !pip install imjoy scikit-image\n","#https://github.com/ZFTurbo/volumentations/blob/4e2c73add77d7fdbc5f69d4248c893f6e6aa67dc/volumentations/augmentations/transforms.py#L154\n","import gc\n","import tensorflow as tf\n","import numpy as np\n","from tensorflow.keras.models import *\n","from tensorflow.keras.optimizers import *\n","from tensorflow.keras.callbacks import *\n","from tensorflow.keras.layers import *\n","import keras.backend as K\n","from itertools import product\n","import os\n","import scipy.io as sio\n","from scipy import ndimage\n","import matplotlib.pyplot as plt\n","\n","from tqdm import tqdm\n","from fastprogress import master_bar, progress_bar\n","import nibabel as nib\n","import glob \n","from mpl_toolkits import mplot3d\n","from IPython.display import clear_output\n","from keras.utils import np_utils\n","from sklearn.feature_extraction.image import extract_patches as sk_extract_patches\n","from sklearn.model_selection import train_test_split\n","from skimage import exposure\n","clear_output()"]},{"cell_type":"markdown","metadata":{"id":"u43BApFJJgT5"},"source":["##Load data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6Xl1tIEhJY7q"},"outputs":[],"source":["TRAIN_PATH = \"/content/data_train/T1*\"\n","PSEUDO_PATH = \"/content/pseudo_data/T1*\"\n","TEST_PATH = \"/content/data_test/T1*\"\n","CROP_SIZE = (144,176,160,1)\n","NUM_CLASS = 4\n","PATCH_SIZE = (32,32,32,1)\n","EXTRACTION_STEP = (8,8,8,1)\n","def normalize(volume):\n","    \"\"\"Normalize the volume\"\"\"\n","    min = 0.0\n","    max = 1000.0\n","    volume = np.clip(volume, min, max)\n","    volume = (volume - min) / (max - min)\n","    return volume\n","\n","def pre_processing(volume, mask = None):\n","    volume = normalize(volume)\n","    volume = CenterCrop(CROP_SIZE).apply(volume)\n","    volume = volume[:,16:,16:,:]\n","    if mask is not None:\n","        mask = CenterCrop(CROP_SIZE).apply(mask)\n","        mask = mask[:,16:,16:,:]\n","        return volume, mask\n","    else :\n","        return volume\n","class patchSequence(tf.keras.utils.Sequence):\n","    def __init__(self, train_path=TRAIN_PATH, test_path= TEST_PATH, \n","               batch_size=16,patch_size = PATCH_SIZE,\n","               shuffle=True, augment=True, typeData = \"train\"):\n","        \n","        try:\n","            self.listT1name =  glob.glob(train_path) + glob.glob(PSEUDO_PATH) if typeData == \"train\" else glob.glob(test_path)\n","        except:\n","            self.listT1name =  glob.glob(train_path) if typeData == \"train\" else glob.glob(test_path)\n","        self.patch_size   = patch_size   \n","        self.batch_size   = batch_size if typeData == \"train\" else batch_size*2 # batch size\n","        self.shuffle      = shuffle             # shuffle bool\n","        self.augment      = augment if typeData == \"train\" else False  # augment data bool\n","        self.typeData = typeData\n","        self.on_epoch_end()\n","        print('data length:', len(self.listT1name))\n","    def __len__(self):\n","        return int(np.floor(len(self.listT1name) / self.batch_size))\n","\n","    def on_epoch_end(self):\n","        self.indexes = np.arange(len(self.listT1name))\n","        if self.shuffle and self.typeData == \"train\":\n","            np.random.shuffle(self.indexes)   \n","\n","    def histogram_equalise_func(self,volume):\n","        squashed_volume = np.reshape(volume, (volume.shape[0], volume.shape[1] * volume.shape[2]))\n","        img_rescale = exposure.equalize_adapthist(squashed_volume, clip_limit=0.01)\n","        img_rescale = np.reshape(img_rescale, volume.shape)\n","        return img_rescale      \n","\n","    def gen_augmentation(self, volume):\n","        if tf.cast(np.random.choice([0, 1],p=[0.75, 0.25]), tf.bool):\n","            volume = exposure.equalize_hist(volume)\n","        return volume\n","\n","    def getBatchData(self, list_IDT1):\n","        volumeT1 = np.zeros((self.batch_size, *self.patch_size))\n","        volumeT2 = np.zeros((self.batch_size, *self.patch_size))\n","        mask = np.zeros((self.batch_size, *self.patch_size))\n","        for i, t1name in enumerate(list_IDT1):\n","            volumeT1[i]= nib.load(t1name).get_fdata()\n","            volumeT2[i]= nib.load(t1name.replace(\"T1\",\"T2\")).get_fdata()\n","            mask[i] = nib.load(t1name.replace(\"T1\",\"mask\")).get_fdata()\n","        ####################### augmentation data ##############################\n","            if self.augment == True:\n","                volumeT1[i] = self.gen_augmentation(volumeT1[i])\n","                volumeT2[i] = self.gen_augmentation(volumeT2[i])\n","        volumeT1 = tf.convert_to_tensor(volumeT1, tf.float32)\n","        volumeT2 = tf.convert_to_tensor(volumeT2, tf.float32)\n","        mask = tf.convert_to_tensor(mask, tf.float32)\n","        return {\"inputT1\": volumeT1,\"inputT2\": volumeT2}, {\"active\": mask, \"levelset\": volumeT1}\n","        # return volumeT1,volumeT2,mask\n","    def __getitem__(self, index):\n","        # selects indices of data for next batch\n","        indexes = self.indexes[index * self.batch_size : (index + 1) * self.batch_size]\n","        # select data and load images\n","        list_IDT1 = [self.listT1name[k] for k in indexes]\n","        return self.getBatchData(list_IDT1)\n","def plot_2Ddata(x, y, numStart = 0, numEnd = 144):\n","    for i in range(numStart, numEnd):\n","        plt.figure(i+1)\n","        plt.subplot(141),plt.imshow(x[0,:,:,i,0]),plt.title('T1')\n","        plt.subplot(142),plt.imshow(x[1,:,:,i,0]),plt.title('T2')\n","        plt.subplot(143),plt.imshow(y[0,:,:,i,0]),plt.title('labelT1')\n","        plt.subplot(144),plt.imshow(y[1,:,:,i,0]),plt.title('labelT2')\n","def inverseLabel(label_raw, predicted):\n","    temp = np.zeros(shape=CROP_SIZE)\n","    temp[:,16:,16:,:]= predicted\n","    return PadIfNeeded(label_raw.shape).apply(temp)  \n","def extract_patches(arr, patch_shape=8, extraction_step=1):\n","    arr_ndim = arr.ndim\n","    patch_strides = arr.strides\n","\n","    slices = [slice(None, None, st) for st in extraction_step]\n","    indexing_strides = arr[tuple(slices)].strides\n","\n","    patch_indices_shape = ((np.array(arr.shape) - np.array(patch_shape)) //\n","                           np.array(extraction_step)) + 1\n","    \n","    shape = tuple(list(patch_indices_shape) + list(patch_shape))\n","    strides = tuple(list(indexing_strides) + list(patch_strides))\n","    patches = np.lib.stride_tricks.as_strided(arr, shape=shape, strides=strides)\n","    npatches = np.prod(patches.shape[:arr_ndim])\n","    return patches.reshape((npatches, ) + patch_shape)\n","\n","def reconstruct_volume_avg(patches, expected_shape, extraction_step = (8,8,8,1), num_class = 4):\n","    v_x, v_y, v_z = expected_shape\n","    p_x, p_y, p_z = patches.shape[1:4]\n","    s_x, s_y, s_z = extraction_step[:3]# compute the dimensions of the patches array\n","    n_x = (v_x - p_x) // s_x + 1\n","    n_y = (v_y - p_y) // s_y + 1\n","    n_z = (v_z - p_z) // s_z + 1\n","\n","    vol = np.zeros((v_x, v_y, v_z, num_class))\n","    count = np.zeros((v_x, v_y, v_z, num_class))\n","\n","    for p, (i, j, k) in zip(patches, product(range(n_x), range(n_y), range(n_z))):\n","        vol[i*s_x:i*s_x+ p_x, j*s_y:j*s_y + p_y, k*s_z:k*s_z + p_z]  +=p\n","        count[i*s_x:i*s_x+ p_x, j*s_y:j*s_y + p_y, k*s_z:k*s_z + p_z] +=1\n","    return vol/count\n","\n","def reconstruct_volume_vote(patches, expected_shape, extraction_step = (8,8,8,1), num_class = 4):\n","    v_x, v_y, v_z = expected_shape\n","    p_x, p_y, p_z = patches.shape[1:4]\n","    s_x, s_y, s_z = extraction_step[:3]# compute the dimensions of the patches array\n","    n_x = (v_x - p_x) // s_x + 1\n","    n_y = (v_y - p_y) // s_y + 1\n","    n_z = (v_z - p_z) // s_z + 1\n","\n","    vol = np.zeros((v_x, v_y, v_z, num_class))\n","\n","    for p, (i, j, k) in zip(patches, product(range(n_x), range(n_y), range(n_z))):\n","        vol[i*s_x:i*s_x+ p_x, j*s_y:j*s_y + p_y, k*s_z:k*s_z + p_z]  += np.where(p<np.max(p, axis = -1,keepdims=True),0, 1)\n","    return vol     \n","    "]},{"cell_type":"markdown","metadata":{"id":"wv9ZNHZBJm-r"},"source":["create numpy file from data\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"c3fBwLUIJY0j"},"outputs":[],"source":["list_T1name =  glob.glob(\"/dataISEG/iSeg-2017-Training/*T1.hdr\")\n","x_trainT1 = []\n","x_trainT2 = []\n","y_train = []\n","for imageNameT1 in list_T1name:\n","    T1_weight = nib.load(imageNameT1).get_fdata().astype(np.float32)\n","    T2_weight = nib.load(imageNameT1.replace(\"T1\", \"T2\")).get_fdata().astype(np.float32)\n","    label = nib.load(imageNameT1.replace(\"T1\", \"label\")).get_fdata().astype(np.float32)\n","    x_trainT1.append(T1_weight)\n","    x_trainT2.append(T2_weight)\n","    y_train.append(label)\n","x_trainT1 = np.stack(x_trainT1)\n","x_trainT2 = np.stack(x_trainT2)\n","y_train = np.stack(y_train)\n","np.save(\"dataISEG_np/T1_train.npy\",x_trainT1)\n","np.save(\"dataISEG_np/T2_train.npy\",x_trainT2 )\n","np.save( \"dataISEG_np/y_train.npy\",y_train)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ms1QdDYJJsJS"},"outputs":[],"source":["t1 = np.load(\"dataISEG_np/T1_train.npy\")\n","t2 = np.load(\"dataISEG_np/T2_train.npy\")\n","mask = np.load(\"dataISEG_np/y_train.npy\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_eehOBqqJsHQ"},"outputs":[],"source":["def gaussian_noise(img):\n","    img = img + np.random.normal(0, 0.1, img.shape)\n","    return np.clip(img, 0, 1)\n","def get_augmentation(x_trainT1, x_trainT2, y_train):\n","    t1 = x_trainT1\n","    t2 = x_trainT2\n","    label = y_train\n","    i=1\n","    for volumeT1, volumeT2, mask in zip(x_trainT1, x_trainT2, y_train):\n","        volumeT1 = gaussian_noise(volumeT1)\n","        volumeT2 = gaussian_noise(volumeT2)\n","\n","        t1 = np.vstack((t1, [volumeT1]))\n","        t2 = np.vstack((t2, [volumeT2]))\n","        label = np.vstack((label, [mask]))\n","    return t1, t2, label\n","# t1, t2, mask = get_augmentation(x_trainT1, x_trainT2, y_train)\n","# np.save(\"dataISEG_np/T1_fullAug.npy\", t1)\n","# np.save(\"dataISEG_np/T2_fullAug.npy\", t2)\n","# np.save(\"dataISEG_np/mask_fullAug.npy\", mask)\n","# t1 = np.load(\"dataISEG_np/T1_fullAug.npy\")\n","# t2 = np.load(\"dataISEG_np/T2_fullAug.npy\")\n","# mask = np.load(\"dataISEG_np/mask_fullAug.npy\")\n","# t1, t2, mask = get_augmentation(t1, t2, mask)"]},{"cell_type":"markdown","metadata":{},"source":["create train_patch32_stride8.zip and test_patch32_stride8.zip"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"A5gSI2iRJsE6"},"outputs":[],"source":["count_train = 1\n","count_test = 1\n","TEST_PATH = \"test_patch32_stride8/\"\n","TRAIN_PATH = \"train_patch32_stride8/\"\n","for i in range(len(mask)):\n","    print(\"\\r read in: \", i+1,\"th volume\", end=\"\")\n","    label_patch = extract_patches(mask[i],PATCH_SIZE,EXTRACTION_STEP)\n","    valid_index = np.where(np.sum(label_patch, axis=(1, 2, 3, 4)) != 0)\n","    y = label_patch[valid_index]\n","    del label_patch\n","\n","    t1_patch = extract_patches(t1[i], PATCH_SIZE, EXTRACTION_STEP)\n","    x_t1 = t1_patch[valid_index]\n","    del t1_patch\n","\n","    t2_patch = extract_patches(t2[i], PATCH_SIZE, EXTRACTION_STEP)\n","    x_t2 = t2_patch[valid_index]\n","    del t2_patch\n","\n","    x_t1_train, x_t1_test, x_t2_train, x_t2_test, y_train, y_test = train_test_split(x_t1, x_t2, y, test_size=0.1)\n","    for j in range(y_train.shape[0]):\n","        print(\"\\rsave \",count_train,\"th volume for train\", end=\"\")             \n","        imgT1 = nib.Nifti1Image( x_t1_train[j], np.eye(4))\n","        nib.save(imgT1, TRAIN_PATH+ 'T1_train_'+str(count_train)+'.nii.gz')  \n","        imgT2 = nib.Nifti1Image( x_t2_train[j], np.eye(4))\n","        nib.save(imgT2, TRAIN_PATH+ 'T2_train_'+str(count_train)+'.nii.gz')  \n","        img_mask = nib.Nifti1Image(y_train[j], np.eye(4))\n","        nib.save(img_mask, TRAIN_PATH+'mask_train_'+str(count_train)+'.nii.gz')    \n","        count_train += 1 \n","\n","    for j in range(y_test.shape[0]):\n","        print(\"\\rsave \",count_test,\"th volume for test\", end=\"\")             \n","        imgT1 = nib.Nifti1Image(x_t1_test[j], np.eye(4))\n","        nib.save(imgT1, TEST_PATH+ 'T1_test_'+str(count_test)+'.nii.gz')  \n","        imgT2 = nib.Nifti1Image(x_t2_test[j], np.eye(4))\n","        nib.save(imgT2, TEST_PATH+ 'T2_test_'+str(count_test)+'.nii.gz')  \n","        img_mask = nib.Nifti1Image(y_test[j], np.eye(4))\n","        nib.save(img_mask, TEST_PATH+'mask_test_'+str(count_test)+'.nii.gz')    \n","        count_test += 1 \n","    del x_t1_train, x_t1_test, x_t2_train, x_t2_test, y_train, y_test, x_t1, x_t2, y\n"]},{"cell_type":"markdown","metadata":{"id":"jZHhqfswJxuC"},"source":["##model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cth7VClvJsCh"},"outputs":[],"source":["# class Swish(tf.keras.layers.Layer):\n","#     def __init__(self, name=None, **kwargs):\n","#         super().__init__(name=name, **kwargs)\n","\n","#     def call(self, inputs, **kwargs):\n","#         return tf.nn.swish(inputs)\n","#     def get_config(self):\n","#         config = super().get_config()\n","#         config['name'] = self.name\n","#         return config\n","# def squeeze_excite_block(inputs, reduce_ratio=0.25,name_block=None):\n","#     filters = inputs.shape[-1]\n","#     num_reduced_filters= max(1, int(filters * reduce_ratio))\n","#     se = Lambda(lambda a: K.mean(a, axis=[1,2,3], keepdims=True))(inputs)\n","\n","#     se = Conv3D(\n","#         num_reduced_filters,\n","#         kernel_size=(1, 1, 1), \n","#         kernel_initializer='he_normal',\n","#         padding='same',\n","#         use_bias=True\n","#         )(se)\n","#     se = Swish()(se)\n","#     se = Conv3D(\n","#         filters,\n","#         kernel_size=(1, 1, 1),\n","#         kernel_initializer='he_normal',\n","#         padding='same',\n","#         use_bias=True\n","#         )(se)\n","#     se = Activation('sigmoid')(se)\n","#     if name_block is not None:\n","#         out = Multiply(name=name_block)([se, inputs])\n","#     else : \n","#         out = Multiply()([se, inputs])\n","#     return out\n","# def conv_block(inputs, filters,kernel_size = (3,3,3), block_name=None):\n","#     x = inputs\n","\n","#     x = Conv3D(filters, kernel_size, padding=\"same\", use_bias=False,kernel_initializer='he_normal')(x)\n","#     x = BatchNormalization()(x)\n","#     x = Swish()(x)\n","\n","#     x = Conv3D(filters, kernel_size, padding=\"same\", use_bias=False,kernel_initializer='he_normal')(x)\n","#     x = BatchNormalization()(x)\n","#     x = Swish()(x)\n","\n","#     x = squeeze_excite_block(x, name_block=block_name)\n","\n","#     return x\n","\n","\n","# def convBn(inputs, filters,kernel_size = (1,1,1), block_name=None):\n","#     x = Conv3D(filters, kernel_size, padding=\"same\", use_bias=False,kernel_initializer='he_normal')(inputs)\n","#     x = BatchNormalization()(x)\n","#     x = Swish()(x)\n","#     x = squeeze_excite_block(x, name_block=block_name)\n","#     return x\n","\n","# def dense_block(inputs, filters, repetition):\n","#     x = inputs\n","#     for _ in range(repetition):\n","#         y = convBn(x, 4 * filters)\n","#         y = convBn(y, filters, (3,3,3))\n","#         x = Concatenate()([y,x])\n","#     return x\n","\n","# def transition_block(inputs):\n","#     indim = inputs.shape[-1] //2 \n","#     x = Conv3D(indim , (1,1,1), padding=\"same\", use_bias=False,kernel_initializer='he_normal')(inputs)\n","#     x = BatchNormalization()(x)\n","#     x = Swish()(x)\n","#     x = squeeze_excite_block(x)\n","#     x = Conv3D(x.shape[-1], (2,2,2),strides=(2,2,2), padding=\"same\", use_bias=False,kernel_initializer='he_normal')(x)\n","#     x = Dropout(0.2)(x)\n","#     return x\n","\n","\n","# def ResidualBlock(inputs):\n","#     x = inputs\n","#     indim= inputs.shape[-1]\n","#     residual = Conv3D(indim,kernel_size=(1,1,1),padding='same')(x)\n","#     residual = BatchNormalization()(residual)\n","#     residual = Swish()(residual)\n","#     residual = Conv3D(indim,kernel_size=(3,3,3),padding='same')(residual)\n","#     residual = BatchNormalization()(residual)\n","#     residual = Swish()(residual)\n","#     residual = Conv3D(indim,kernel_size=(1,1,1),padding='same')(residual)\n","#     residual = BatchNormalization()(residual)\n","#     residual = Swish()(residual)\n","\n","#     x        = BatchNormalization()(x)\n","#     #residual = Dropout(0.2)(residual)\n","#     out = x+ residual\n","    \n","#     return out\n","# def attention_module(inputs, skip, n_filter):\n","#     x = Conv3D(n_filter,(1, 1,1), padding='same', kernel_initializer='he_normal',use_bias=False)(inputs)\n","#     x = BatchNormalization()(x)\n","#     x = Conv3DTranspose(n_filter, (2,2,2), strides=(2, 2,2), padding='same',kernel_initializer = 'he_normal')(x)\n","\n","#     x1= Conv3D(n_filter,(1, 1,1), padding='same', kernel_initializer='he_normal',use_bias=False)(skip)\n","#     x1 = BatchNormalization()(x1)\n","\n","#     out = Swish()(x1+x)\n","#     out = Conv3D(1,(1, 1,1), padding='same', kernel_initializer='he_normal',use_bias=False)(out)\n","#     out = BatchNormalization()(out)\n","#     out = Activation('sigmoid')(out)\n","\n","#     return out*skip\n","\n","# def decoder_block(inputs, n_filter,skip=None):\n","#     x= Conv3DTranspose(n_filter, (2,2,2), strides=(2, 2, 2), padding='same',kernel_initializer = 'he_normal')(inputs)\n","#     out = x\n","#     if skip is not None :\n","#         attention = attention_module(inputs,skip, n_filter)\n","#         out = Concatenate()([x,attention])\n","#     # out = conv_block(out, n_filter)\n","#     out = convBn(out, out.shape[-1])\n","\n","#     return out\n","# def seg_net(input_shape= (32,32,32,1), out_channels = 4):\n","#     # inp = Input(shape=input_shape)\n","#     # o = transition_block(16)(inp)\n","#     inpT1 = Input(shape=input_shape, name=\"inputT1\")\n","#     inpT2 = Input(shape=input_shape, name=\"inputT2\")\n","\n","#     oT1 = convBn(inpT1, 16)\n","#     oT2 = convBn(inpT2, 16)\n","#     o = Concatenate()([oT1, oT2])\n","#     o = convBn(o, 32)\n","\n","#     skip1 = dense_block(o, 16, repetition = 4)\n","#     o = transition_block(skip1)\n","\n","#     skip2 = dense_block(o, 16, repetition = 4)\n","#     o = transition_block(skip2)\n","\n","#     skip3 = dense_block(o, 16, repetition = 4)\n","#     o = transition_block(skip3)\n","\n","#     skip4 = dense_block(o, 16, repetition = 4)\n","#     o = transition_block(skip4)\n","\n","\n","#     o = conv_block(o, 128)\n","#     o = Dropout(0.2)(o)\n","#     skip_connect = [skip4, skip3, skip2, skip1]\n","\n","#     num_filters = [64, 64, 32, 16]\n","#     for i, f in enumerate(num_filters):\n","#         o = decoder_block(o, f,skip=skip_connect[i])\n","#         o = Dropout(0.1)(o)\n","    \n","#     o = Conv3D(out_channels,(1, 1 ,1), padding='same', kernel_initializer='he_normal')(o)\n","#     # o = BatchNormalization()(o)\n","#     if out_channels > 1 : \n","#         output1 = Activation('softmax', name = \"active\")(o)\n","#         output2 = Activation('softmax', name = \"levelset\")(o)\n","#     else :\n","#         output1 = Activation('sigmoid', name = \"active\")(o)\n","#         output2 = Activation('sigmoid', name = \"levelset\")(o)\n","#     return Model([inpT1, inpT2], [output1, output2])\n","\n","# # S=seg_net()\n","# # S.summary()"]},{"cell_type":"markdown","metadata":{"id":"F0DXvDSBaupX"},"source":["##train"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gztnyR1_JsAi"},"outputs":[],"source":["def dice_coef(y_true, y_pred, smooth=1):\n","    intersection = K.sum(y_true * y_pred, axis=[1,2,3,4])\n","    union = K.sum(y_true, axis=[1,2,3,4]) + K.sum(y_pred, axis=[1,2,3,4])\n","    return K.mean( (2. * intersection + smooth) / (union + smooth), axis=0)\n","\n","def dice_CSF(y_true, y_pred, smooth = 1.0):\n","    output_standard = K.expand_dims(K.argmax(y_pred,axis=-1), axis=-1)\n","    output_CSF = tf.where(output_standard == 1, 1.0, 0.0)\n","    label_CSF = tf.where(y_true == 1, 1.0, 0.0)\n","\n","    intersection = K.sum(label_CSF * output_CSF, axis=[1,2,3,4])\n","    union = K.sum(label_CSF, axis=[1,2,3,4]) + K.sum(output_CSF, axis=[1,2,3,4])\n","    return K.mean((2. * intersection + smooth) / (union + smooth), axis=0)\n","\n","def dice_GM(y_true, y_pred, smooth = 1.0):\n","    output_standard = K.expand_dims(K.argmax(y_pred,axis=-1), axis=-1)\n","    output_GM = tf.where(output_standard == 2, 1.0, 0.0)\n","    label_GM = tf.where(y_true == 2, 1.0, 0.0)\n","\n","    intersection = K.sum(label_GM * output_GM, axis=[1,2,3,4])\n","    union = K.sum(label_GM, axis=[1,2,3,4]) + K.sum(output_GM, axis=[1,2,3,4])\n","    return K.mean((2. * intersection + smooth) / (union + smooth), axis=0)\n","\n","def dice_WM(y_true, y_pred, smooth = 1.0):\n","    output_standard = K.expand_dims(K.argmax(y_pred,axis=-1), axis=-1)\n","    output_WM = tf.where(output_standard == 3, 1.0, 0.0)\n","    label_WM = tf.where(y_true == 3, 1.0, 0.0)\n","\n","    intersection = K.sum(label_WM * output_WM, axis=[1,2,3,4])\n","    union = K.sum(label_WM, axis=[1,2,3,4]) + K.sum(output_WM, axis=[1,2,3,4])\n","    return K.mean((2. * intersection + smooth) / (union + smooth), axis=0)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Q6x52-l4Jr-T"},"outputs":[],"source":["def gradientLoss(y_pred,penalty = \"l1\"):\n","\n","    dH = tf.math.abs(y_pred[:,1:,...] - y_pred[:,:-1,...])\n","    dW = tf.math.abs(y_pred[:,:,1:,...] - y_pred[:,:,:-1,...])\n","    dD = tf.math.abs(y_pred[...,1:,:] - y_pred[...,:-1,:])\n","    if penalty == \"l2\":\n","        dH = dH * dH\n","        dW = dW * dW\n","        dD = dD * dD\n","\n","    loss =  tf.reduce_sum(dH) +  tf.reduce_sum(dW)+ tf.reduce_sum(dD)\n","    return loss\n","# def levelsetLoss(volume, y_pred, kernel_size = 3, beta = 1e-3):\n","#     kernel = tf.ones([kernel_size, kernel_size, kernel_size, 1, y_pred.shape[-1]],tf.float32) / (kernel_size**3)\n","      \n","#     pcentroid_1 = tf.nn.conv3d( volume * y_pred, kernel, strides=[1,1,1,1,1], padding='SAME')\n","#     pcentroid_2 =  tf.nn.conv3d(y_pred + 1e-7, kernel, strides=[1,1,1,1,1], padding='SAME')\n","#     pcentroid = pcentroid_1 / pcentroid_2\n","#     plevel = volume - pcentroid\n","#     loss = plevel * plevel * y_pred\n","\n","#     lossLength = gradientLoss(y_pred)\n","#     # lossLength = 0\n","#     return tf.reduce_sum(loss) + beta * lossLength\n","def levelsetLossCVES(volume, y_pred,  beta = 1e-3):\n","    lossRegion = 0.0\n","    pcentroid = tf.reduce_sum(volume**2 * y_pred, (1,2,3),keepdims=True)/tf.reduce_sum(volume* y_pred+1e-10, (1,2,3),keepdims = True)   \n","    plevel = (volume - pcentroid) / pcentroid\n","\n","    loss = plevel * plevel * y_pred\n","    lossRegion += tf.reduce_sum(loss)\n","    \n","    lossLength = gradientLoss(y_pred)\n","    return tf.reduce_sum(lossRegion) + beta * lossLength\n","\n","def ActiveContourLoss(y_true, y_pred, smooth=1e-7):   \n","    maskOnehot = tf.one_hot(tf.squeeze(tf.cast(y_true,tf.uint8),axis=-1), depth = NUM_CLASS)\n","    # lossAC =  y_pred * (1-maskOnehot) + (1-y_pred)*maskOnehot\n","    # lossAC = 0\n","    #######################  this is Luac:##############\n","    lossAC =  - tf.cast(tf.math.log(1-y_pred+smooth),tf.float32) * (1-maskOnehot) - tf.cast(tf.math.log(y_pred+smooth),tf.float32)*maskOnehot\n","\n","    return tf.reduce_mean(lossAC)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"x9xvBLMHJr78"},"outputs":[],"source":["# S = seg_net(input_shape=PATCH_SIZE)\n","# S.compile(optimizer=Nadam(learning_rate=5e-4), loss={\"active\":ActiveContourLoss, \"levelset\":levelsetLoss},\\\n","#         loss_weights={\"active\": 1.0, \"levelset\": 1e-6},\\\n","#         metrics={\"active\": [dice_CSF, dice_GM, dice_WM]})\n","mcp = ModelCheckpoint(\"./weightTraining/ckpt{val_active_dice_WM:.4f}.h5\",mode='max',monitor='val_active_dice_WM',verbose=1,save_best_only=True,save_weights_only=True)\n","earlystop= EarlyStopping(monitor='val_active_dice_WM',patience=150,mode='max',verbose=1)\n","rlr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_active_dice_WM', factor=0.5, mode='max', patience=3, min_lr=1e-7, verbose=1)\n","csv_logger = CSVLogger(\"history.csv\",append= True)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":828,"status":"ok","timestamp":1629823629860,"user":{"displayName":"Minh Nhật Trịnh","photoUrl":"","userId":"05773131169689709632"},"user_tz":-420},"id":"O5HO4g96b9_T","outputId":"52085785-a4c4-4dea-bd9f-82552eb98107"},"outputs":[{"name":"stdout","output_type":"stream","text":["data length: 0\n","data length: 3384\n"]}],"source":["train_dataset = patchSequence(batch_size= 16, augment = False)\n","test_dataset = patchSequence(batch_size= 32, typeData=\"test\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sO954MyxP3V7"},"outputs":[],"source":["# S.save_weights(\"current.h5\")\n","# S = seg_net(input_shape=PATCH_SIZE, keep_prob= 1)\n","# S.load_weights(\"current.h5\")\n","# S.load_weights(\"weightTraining/ckpt0.9666.h5\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ev6qEBWQPNfC"},"outputs":[],"source":["# for keep_prob in np.linspace(start = 0.99, stop = 1, num=6):\n","#     print(\"dropout rate is:\", keep_prob)\n","#     new_model = seg_net(input_shape=PATCH_SIZE, keep_prob = keep_prob)\n","#     new_model.set_weights(S.get_weights())\n","#     S = new_model\n","#     S.compile(optimizer=Nadam(learning_rate=2.5e-5), loss={\"active\":ActiveContourLoss, \n","#                                                          \"levelset\":levelsetLossCVES},\\\n","#             loss_weights={\"active\": 1.0, \"levelset\": 1e-9},\\\n","#             metrics={\"active\": [dice_CSF, dice_GM, dice_WM]})\n","#     S.fit(train_dataset,epochs = 4, callbacks=[mcp, rlr,earlystop,csv_logger],\\\n","#       validation_data=test_dataset)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_XdtQfDNjgg4"},"outputs":[],"source":["# S = seg_net(input_shape=PATCH_SIZE,keep_prob= 1)\n","# # S.load_weights(\"weightTraining2/ckpt0.9280.h5\")\n","# for keep_prob in np.linspace(start = 1, stop = 0.9, num=51):\n","#     print(\"dropout rate is:\", keep_prob)\n","#     new_model = seg_net(input_shape=PATCH_SIZE, keep_prob = keep_prob)\n","#     new_model.set_weights(S.get_weights())\n","#     S = new_model\n","#     S.compile(optimizer=Nadam(learning_rate=5e-4), loss={\"active\":ActiveContourLoss, \n","#                                                          \"levelset\":levelsetLossCVES},\\\n","#             loss_weights={\"active\": 1.0, \"levelset\": 1e-9},\\\n","#             metrics={\"active\": [dice_CSF, dice_GM, dice_WM]})\n","#     S.fit(train_dataset,epochs = 1, callbacks=[mcp, rlr,earlystop,csv_logger],\\\n","#       validation_data=test_dataset)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sdgHDptVeUw0"},"outputs":[],"source":["S = seg_net(input_shape=PATCH_SIZE, keep_prob= 0.998)\n","S.compile(optimizer=Nadam(learning_rate=2.5e-5), loss={\"active\":ActiveContourLoss, \n","                                                        \"levelset\":levelsetLossCVES},\\\n","        loss_weights={\"active\": 1.0, \"levelset\": 1e-9},\\\n","        metrics={\"active\": [dice_CSF, dice_GM, dice_WM]})"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7A-1QZI4Fl_t"},"outputs":[],"source":["S.load_weights(\"./weightTraining/ckpt0.9595.h5\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":54757,"status":"ok","timestamp":1629826041581,"user":{"displayName":"Minh Nhật Trịnh","photoUrl":"","userId":"05773131169689709632"},"user_tz":-420},"id":"POb7OzmX7L_N","outputId":"dc208a0f-bc8d-42f0-b7a7-6522e2be984e"},"outputs":[{"name":"stdout","output_type":"stream","text":["52/52 [==============================] - 54s 724ms/step - loss: 0.0084 - active_loss: 0.0072 - levelset_loss: 1202888.3750 - active_dice_CSF: 0.9884 - active_dice_GM: 0.9718 - active_dice_WM: 0.9593\n"]},{"data":{"text/plain":["[0.008379052393138409,\n"," 0.007176163140684366,\n"," 1202888.375,\n"," 0.98841392993927,\n"," 0.9717748165130615,\n"," 0.9593257904052734]"]},"execution_count":17,"metadata":{},"output_type":"execute_result"}],"source":["S.evaluate(test_dataset)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MY8nGx5SB5hw"},"outputs":[],"source":["S.fit(train_dataset,epochs = 1000, callbacks=[mcp, rlr,earlystop,csv_logger], \\\n","      validation_data=test_dataset)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Bw1EkJDzJxOi"},"outputs":[],"source":["# for layer in S.layers:\n","#     if isinstance(layer, DropBlock3D):\n","#         print(layer.block_size)\n","# S = load_model(\"model_U_Unet.h5\",\n","#                custom_objects={\"Swish\":Swish,\"DropBlock3D\":DropBlock3D}, compile=False)\n","# S.compile(optimizer=Nadam(learning_rate=1.25e-4), loss={\"active\":ActiveContourLoss, \n","#                                                         \"levelset\":levelsetLossCVES},\\\n","#         loss_weights={\"active\": 1.0, \"levelset\": 1e-9},\\\n","#         metrics={\"active\": [dice_CSF, dice_GM, dice_WM]})\n","# S.evaluate(test_dataset)"]},{"cell_type":"markdown","metadata":{"id":"CdehVOL0NwYM"},"source":["##psedo labeling\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"V04xssgQN1PD"},"outputs":[],"source":["def getValidIndex(label_constructed, patchT1, threshold):\n","    filter = np.max(label_constructed, axis=-1,keepdims=True)\n","    patch = extract_patches(filter, PATCH_SIZE, EXTRACTION_STEP)\n","    valid_index = []\n","    for index in range(patch.shape[0]):\n","        if (not False in np.unique(patch[index] > threshold)) and np.sum(patchT1[index]) != 0:\n","            valid_index.append(index)\n","    return valid_index\n","# IMG_SUBMIT_PATH = \"/dataISEG/iSeg-2019-Validation/\"\n","# LABEL_SUBMIT_PATH = \"/dataISEG/iSeg-2017-Test-Prob/\"\n","# for i in range(11,24):\n","#     print(\"\\rsegment : {}th subject\".format(i), end=\"\")\n","#     imgT1 = nib.load(IMG_SUBMIT_PATH+\"subject-\"+str(i)+\"-T1.hdr\").get_fdata()\n","#     imgT1 = normalize(imgT1)\n","#     imgT2 = nib.load(IMG_SUBMIT_PATH+\"subject-\"+str(i)+\"-T2.hdr\").get_fdata()\n","#     imgT2 = normalize(imgT2)\n","#     patchT1 = extract_patches(imgT1, PATCH_SIZE, EXTRACTION_STEP)\n","#     patchT2 = extract_patches(imgT2, PATCH_SIZE, EXTRACTION_STEP)\n","\n","#     pred = np.zeros((*patchT1.shape[:-1], NUM_CLASS))\n","#     pred[...,0] = 1\n","#     valid_index = np.where(np.sum(patchT1, axis=(1, 2, 3, 4)) != 0)\n","#     patchT1_valid = tf.convert_to_tensor(patchT1[valid_index], tf.float32)\n","#     patchT2_valid = tf.convert_to_tensor(patchT2[valid_index], tf.float32)\n","#     del patchT1, patchT2\n","#     temp = S.predict({\"inputT1\": patchT1_valid, \n","#                         \"inputT2\": patchT2_valid}, batch_size = 32)[0]\n","#     gc.collect()\n","#     K.clear_session()\n","#     pred[valid_index] = temp\n","#     del valid_index, temp, patchT1_valid, patchT2_valid\n","#     label_constructed = reconstruct_volume_avg(pred, imgT1.shape[:-1], EXTRACTION_STEP)\n","#     del imgT1, imgT2, pred\n","#     label_save = nib.Nifti1Image(label_constructed, np.eye(4))\n","#     nib.save(label_save, LABEL_SUBMIT_PATH+\"subject-\"+str(i)+\"-label.nii.gz\")    \n","#     del label_constructed, label_save\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":520924,"status":"ok","timestamp":1624175158593,"user":{"displayName":"Minh Nhật Trịnh","photoUrl":"","userId":"05773131169689709632"},"user_tz":-420},"id":"IOFR6k56kruh","outputId":"4b0807b4-8c25-4752-d032-4d870a17a6b2"},"outputs":[{"name":"stdout","output_type":"stream","text":["save  37820 th volume for train"]}],"source":["# count_train = 1\n","# PSEUDO_PATH = \"/content/pseudo_data/\"\n","# GET_LABEL_PATH  = \"dataISEG/iSeg-2017-Test-Prob/\"\n","# GET_IMAGE_PATH  = \"dataISEG/iSeg-2017-Testing/\"\n","# for i in range(11, 24):\n","#     label_constructed = nib.load(GET_LABEL_PATH+\"subject-\"+str(i)+\"-label.nii.gz\").get_fdata()\n","#     imgT1 = nib.load(GET_IMAGE_PATH+\"subject-\"+str(i)+\"-T1.hdr\").get_fdata()\n","#     imgT1 = normalize(imgT1)\n","#     patchT1 = extract_patches(imgT1, PATCH_SIZE, EXTRACTION_STEP)\n","#     valid_index = getValidIndex(label_constructed, patchT1, 0.5)\n","\n","#     x_t1 = patchT1[valid_index]\n","#     del patchT1, imgT1\n","#     output_standard = np.expand_dims(np.argmax(label_constructed, axis=-1), axis=-1)\n","#     label_patch = extract_patches(output_standard,PATCH_SIZE,EXTRACTION_STEP)\n","#     label = label_patch[valid_index]\n","#     del label_patch, output_standard, label_constructed\n","#     imgT2 = nib.load(GET_IMAGE_PATH+\"subject-\"+str(i)+\"-T2.hdr\").get_fdata()\n","#     imgT2 = normalize(imgT2)\n","#     patchT2 = extract_patches(imgT2, PATCH_SIZE, EXTRACTION_STEP)\n","#     x_t2 = patchT2[valid_index]\n","#     del patchT2, imgT2 \n","\n","#     for j in range(len(valid_index)):\n","#         print(\"\\rsave \",count_train,\"th volume for train\", end=\"\")             \n","#         imgT1 = nib.Nifti1Image( x_t1[j], np.eye(4))\n","#         nib.save(imgT1, PSEUDO_PATH+ 'T1_train_'+str(count_train)+'.nii.gz')  \n","#         imgT2 = nib.Nifti1Image( x_t2[j], np.eye(4))\n","#         nib.save(imgT2, PSEUDO_PATH+ 'T2_train_'+str(count_train)+'.nii.gz')  \n","#         img_mask = nib.Nifti1Image(label[j], np.eye(4))\n","#         nib.save(img_mask, PSEUDO_PATH+'mask_train_'+str(count_train)+'.nii.gz')    \n","#         count_train += 1 \n","# import shutil\n","# shutil.make_archive(\"pseudo_data\", \"zip\",\"/content/pseudo_data\") "]},{"cell_type":"markdown","metadata":{"id":"tJeH2AGxNt_T"},"source":["##submit"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aY8GR_dPq-hB"},"outputs":[],"source":["def convertLable2Submit(label):\n","    class_mapper_inv = {1 : 10, 2 : 150, 3 : 250}\n","    for key, value in class_mapper_inv.items():\n","        label = np.where(label==key, value, label)\n","    return label.astype(np.uint8)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5t4-nDMNKCjY"},"outputs":[],"source":["S = load_model(\"model_U_Unet.h5\",\n","               custom_objects={\"Swish\":Swish,\"DropBlock3D\":DropBlock3D}, compile=False)"]},{"cell_type":"markdown","metadata":{},"source":["access performance on training-set"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HNhZbMW7Q6Os"},"outputs":[],"source":["# dice_csf = []\n","# dice_gm = []\n","# dice_wm = []\n","# for j in range(1,3):\n","#     imgT1 = nib.load(\"dataISEG/iSeg-2019-Training/subject-\"+str(j)+\"-T1.hdr\").get_fdata()\n","#     imgT1 = normalize(imgT1)\n","#     imgT2 = nib.load(\"dataISEG/iSeg-2019-Training/subject-\"+str(j)+\"-T2.hdr\").get_fdata()\n","#     imgT2 = normalize(imgT2)\n","#     label = nib.load(\"dataISEG/iSeg-2019-Training/subject-\"+str(j)+\"-label.hdr\").get_fdata()\n","#     patchT1 = extract_patches(imgT1, PATCH_SIZE, EXTRACTION_STEP)\n","#     patchT2 = extract_patches(imgT2, PATCH_SIZE, EXTRACTION_STEP)\n","\n","#     pred = np.zeros((*patchT1.shape[:-1], NUM_CLASS))\n","#     pred[...,0] = 1\n","#     valid_index = np.where(np.sum(patchT1, axis=(1, 2, 3, 4)) != 0)\n","#     patchT1_valid = tf.convert_to_tensor(patchT1[valid_index], tf.float32)\n","#     patchT2_valid = tf.convert_to_tensor(patchT2[valid_index], tf.float32)\n","#     del patchT1, patchT2\n","#     temp = S.predict({\"inputT1\": patchT1_valid, \n","#                         \"inputT2\": patchT2_valid}, batch_size = 32)[0]\n","#     gc.collect()\n","#     K.clear_session()\n","#     pred[valid_index] = temp\n","#     del valid_index, temp, patchT1_valid, patchT2_valid\n","#     label_constructed = reconstruct_volume_avg(pred, imgT1.shape[:-1], EXTRACTION_STEP)\n","#     output_standard = tf.expand_dims(tf.argmax(label_constructed,axis=-1), axis=-1)\n","#     del imgT1, imgT2, pred, label_constructed\n","#     for i in range(1,4):\n","#         output_CSF = np.where(output_standard == i, 1.0, 0.0)\n","#         label_CSF = np.where(label == i, 1.0, 0.0)\n","\n","#         intersection = K.sum(label_CSF * output_CSF, axis=[0,1,2,3])\n","#         union = K.sum(label_CSF, axis=[0,1,2,3]) + K.sum(output_CSF, axis=[0,1,2,3])\n","#         dice = ((2. * intersection + 1) / (union + 1))\n","#         if i==1:\n","#             dice_csf.append(dice)\n","#         elif i==2:\n","#             dice_gm.append(dice)\n","#         else : \n","#             dice_wm.append(dice)\n","#         print(f\"subject {j}: \", dice)\n","#     del intersection, union, dice, label, output_standard     \n","# del patchT1_valid, patchT2_valid\n","# print(np.mean(dice_csf), np.mean(dice_gm),np.mean(dice_wm))                    "]},{"cell_type":"markdown","metadata":{},"source":["create files to submit"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":634672,"status":"ok","timestamp":1625561645706,"user":{"displayName":"Minh Nhật Trịnh","photoUrl":"","userId":"05773131169689709632"},"user_tz":-420},"id":"QORzoxVFLeih","outputId":"df5b3e15-dc6e-4f36-b058-0ca85eb175b0"},"outputs":[{"name":"stdout","output_type":"stream","text":["segment : 23th subject"]}],"source":["IMG_SUBMIT_PATH = \"dataISEG/iSeg-2017-Testing/\"\n","LABEL_SUBMIT_PATH = \"dataISEG/iSeg-2017-Test-Label/\"\n","for i in range(11,24):\n","    print(\"\\rsegment : {}th subject\".format(i), end=\"\")\n","    imgT1 = nib.load(IMG_SUBMIT_PATH+\"subject-\"+str(i)+\"-T1.hdr\").get_fdata()\n","    imgT1 = normalize(imgT1)\n","    imgT2 = nib.load(IMG_SUBMIT_PATH+\"subject-\"+str(i)+\"-T2.hdr\").get_fdata()\n","    imgT2 = normalize(imgT2)\n","    patchT1 = extract_patches(imgT1, PATCH_SIZE, EXTRACTION_STEP)\n","    patchT2 = extract_patches(imgT2, PATCH_SIZE, EXTRACTION_STEP)\n","\n","    pred = np.zeros((*patchT1.shape[:-1], NUM_CLASS))\n","    pred[...,0] = 1\n","    valid_index = np.where(np.sum(patchT1, axis=(1, 2, 3, 4)) != 0)\n","    patchT1_valid = tf.convert_to_tensor(patchT1[valid_index], tf.float32)\n","    patchT2_valid = tf.convert_to_tensor(patchT2[valid_index], tf.float32)\n","    del patchT1, patchT2\n","    temp = S.predict({\"inputT1\": patchT1_valid, \n","                        \"inputT2\": patchT2_valid}, batch_size = 32)[0]\n","    gc.collect()\n","    K.clear_session()\n","    pred[valid_index] = temp\n","    del valid_index, temp, patchT1_valid, patchT2_valid\n","    label_constructed = reconstruct_volume_avg(pred, imgT1.shape[:-1], EXTRACTION_STEP)\n","    output_standard = np.expand_dims(np.argmax(label_constructed, axis=-1), axis=-1)\n","    output_standard = convertLable2Submit(output_standard)\n","    del imgT1, imgT2, pred, label_constructed\n","\n","    label_save = nib.Nifti1Image(output_standard, np.eye(4))\n","    nib.nifti1.save(label_save, LABEL_SUBMIT_PATH+\"subject-\"+str(i)+\"-label.hdr\")\n","    del output_standard"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":["wv9ZNHZBJm-r","jZHhqfswJxuC"],"machine_shape":"hm","name":"train.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3.7.13 ('stable_env')","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.7.13"},"vscode":{"interpreter":{"hash":"f4c44228236846489b48d7ca3d9c352a36fad9df41b333a127a7d80da5b1990b"}}},"nbformat":4,"nbformat_minor":0}
