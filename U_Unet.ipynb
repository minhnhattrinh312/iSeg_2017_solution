{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"AWK4ruvFghxH"},"outputs":[],"source":["import tensorflow as tf\n","import numpy as np\n","from tensorflow.keras.models import *\n","from tensorflow.keras.layers import *\n","import keras.backend as K"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SSre0ptdo0-8"},"outputs":[],"source":["def _bernoulli(shape, mean):\n","    return tf.nn.relu(tf.sign(mean - tf.random.uniform(shape, minval=0, maxval=1, dtype=tf.float32)))\n","class DropBlock2D(tf.keras.layers.Layer):\n","    def __init__(self, keep_prob, block_size, scale=True,name=None, **kwargs):\n","        super(DropBlock2D, self).__init__(name=\"DropBlock2D\")\n","        self.keep_prob = min(1.0, max(float(keep_prob), 0))\n","        self.block_size = int(block_size)\n","        self.names = name\n","        self.scale = tf.constant(scale, dtype=tf.bool) if isinstance(scale, bool) else scale\n","        super(DropBlock2D, self).__init__(**kwargs)\n","        \n","    def get_config(self):\n","        config = super().get_config().copy()\n","        config.update( {\"block_size\": self.block_size,\"keep_prob\":  self.keep_prob,\"name\": self.names})  \n","        return config\n","\n","    def compute_output_shape(self, input_shape):\n","        return input_shape\n","\n","    def build(self, input_shape):\n","        assert len(input_shape) == 4\n","        _, self.h, self.w, self.channel = input_shape.as_list()\n","        # pad the mask\n","        p1 = (self.block_size - 1) // 2\n","        p0 = (self.block_size - 1) - p1\n","        self.padding = [[0, 0], [p0, p1], [p0, p1], [0, 0]]\n","        super(DropBlock2D, self).build(input_shape)\n","\n","    def call(self, inputs, training=None, **kwargs):\n","        def drop():\n","            mask = self._create_mask(tf.shape(inputs))\n","            output = inputs * mask\n","            output = tf.cond(self.scale,\n","                             true_fn=lambda: output *tf.cast(tf.size(mask), dtype=tf.float32)  / tf.reduce_sum(mask),\n","                             false_fn=lambda: output)\n","            return output\n","\n","        if training is None:\n","            training = K.learning_phase()\n","            training = tf.cast(training, tf.bool)\n","        output = tf.cond(tf.logical_or(tf.logical_not(training), tf.equal(self.keep_prob, 1.0)),\n","                         true_fn=lambda: inputs,\n","                         false_fn=drop)\n","        return output\n","    def _create_mask(self, input_shape):\n","        self.gamma = (1. - self.keep_prob) * (self.w * self.h) / (self.block_size ** 2) / \\\n","                     ((self.w - self.block_size + 1) * (self.h - self.block_size + 1))\n","        sampling_mask_shape = tf.stack([input_shape[0],\n","                                       self.h - self.block_size + 1,\n","                                       self.w - self.block_size + 1,\n","                                       self.channel])\n","        mask = _bernoulli(sampling_mask_shape, self.gamma)\n","        mask = tf.pad(mask, self.padding)\n","        mask = tf.nn.max_pool(mask, [1, self.block_size, self.block_size, 1], [1, 1, 1, 1], 'SAME')\n","        mask = 1 - mask\n","        return mask\n","\n","class DropBlock3D(tf.keras.layers.Layer):\n","    def __init__(self, keep_prob, block_size, scale=True,name=None, **kwargs):\n","        super(DropBlock3D, self).__init__(name=\"DropBlock3D\")\n","        self.keep_prob = min(1.0, max(float(keep_prob), 0))\n","        self.block_size = int(block_size)\n","        self.names = name\n","        self.scale = tf.constant(scale, dtype=tf.bool) if isinstance(scale, bool) else scale\n","        super(DropBlock3D, self).__init__(**kwargs)\n","\n","    def get_config(self):\n","        config = super().get_config().copy()\n","        config.update( {\"block_size\": self.block_size,\"keep_prob\":  self.keep_prob,\"name\": self.names})  \n","        return config\n","        \n","    def compute_output_shape(self, input_shape):\n","        return input_shape\n","\n","    def build(self, input_shape):\n","        assert len(input_shape) == 5\n","        _, self.d, self.h, self.w, self.channel = input_shape.as_list()\n","        # pad the mask\n","        p1 = (self.block_size - 1) // 2\n","        p0= (self.block_size - 1) - p1\n","        self.padding = [[0, 0], [p0, p1], [p0, p1], [p0, p1], [0, 0]]\n","        super(DropBlock3D, self).build(input_shape)\n","    \n","    def call(self, inputs, training=None, **kwargs):\n","        def drop():\n","            mask = self._create_mask(tf.shape(inputs))\n","            output = inputs * mask\n","            output = tf.cond(self.scale,\n","                             true_fn=lambda: output * tf.cast(tf.size(mask), dtype=tf.float32)  / tf.reduce_sum(mask),\n","                             false_fn=lambda: output)\n","            return output\n","        if training is None:\n","            training = K.learning_phase()\n","            training = tf.cast(training, tf.bool)\n","        output = tf.cond(tf.logical_or(tf.logical_not(training), tf.equal(self.keep_prob, 1.0)),\n","                         true_fn=lambda: inputs,\n","                         false_fn=drop)\n","        return output\n","    def _create_mask(self, input_shape):\n","        self.gamma = ((1. - self.keep_prob) * (self.d * self.w * self.h) / (self.block_size ** 3) /\n","                    ((self.d - self.block_size + 1) * (self.w - self.block_size + 1) * (self.h - self.block_size + 1)))\n","        sampling_mask_shape = tf.stack([input_shape[0],\n","                                        self.d - self.block_size + 1,\n","                                        self.h - self.block_size + 1,\n","                                        self.w - self.block_size + 1,\n","                                        self.channel])\n","        mask = _bernoulli(sampling_mask_shape, self.gamma)\n","        mask = tf.pad(mask, self.padding)\n","        mask = tf.nn.max_pool3d(mask, [1, self.block_size, self.block_size, self.block_size, 1], [1, 1, 1, 1, 1], 'SAME')\n","        mask = 1 - mask\n","        return mask"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HMpkrg0k9OZY"},"outputs":[],"source":["# import numpy as np\n","# import tensorflow as tf\n","# # only support `channels_last` data format\n","# a = Input(shape=(4,4,4,10))\n","# b = DropBlock3D(block_size=3, keep_prob=0)(a)\n","\n","# model = Model(a,b)\n","\n","# for layer in model.layers:\n","#     if isinstance(layer, DropBlock3D):\n","#         print(layer.gamma)\n","# output = model(np.ones([1,4,4,4,1]), training = True)\n","# output"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2nH1ExF1laf6"},"outputs":[],"source":["def cbam_block(cbam_feature, ratio=8):\n","\t\"\"\"Contains the implementation of Convolutional Block Attention Module(CBAM) block.\n","\tAs described in https://arxiv.org/abs/1807.06521.\n","\t\"\"\"\n","\tcbam_feature = channel_attention(cbam_feature, ratio)\n","\tcbam_feature = spatial_attention(cbam_feature)\n","\treturn cbam_feature\n","\n","def channel_attention(input_feature, ratio=8):\n","    channel = input_feature.shape[-1]\n","    num_reduced_filters= max(1, int(channel // ratio))\n","    avg_pool = Lambda(lambda a: K.mean(a, axis=[1,2,3], keepdims=True))(input_feature)\n","    avg_pool = Conv3D(num_reduced_filters, kernel_size=(1, 1, 1), kernel_initializer='he_normal',\n","                        padding='same',use_bias=True)(avg_pool)\n","    avg_pool = Swish()(avg_pool)\n","    avg_pool = Conv3D(channel, kernel_size=(1, 1, 1), kernel_initializer='he_normal',\n","                        padding='same',use_bias=True)(avg_pool)\n","\n","    max_pool = Lambda(lambda a: K.mean(a, axis=[1,2,3], keepdims=True))(input_feature)\n","    max_pool = Conv3D(num_reduced_filters, kernel_size=(1, 1, 1), kernel_initializer='he_normal',\n","                        padding='same',use_bias=True)(max_pool)\n","    max_pool = Swish()(max_pool)\n","    max_pool = Conv3D(channel, kernel_size=(1, 1, 1), kernel_initializer='he_normal',\n","                        padding='same',use_bias=True)(max_pool)\n","\n","    cbam_feature = Add()([avg_pool,max_pool])\n","    cbam_feature = Activation('sigmoid')(cbam_feature)\n","\n","    output = Multiply()([input_feature, cbam_feature])\n","    return output\n","\n","def spatial_attention(input_feature):\n","    kernel_size = 7\n","    channel = input_feature.shape[-1]\n","    cbam_feature = input_feature\n","\n","    avg_pool = Lambda(lambda x: K.mean(x, axis=-1, keepdims=True))(cbam_feature)\n","    max_pool = Lambda(lambda x: K.max(x, axis=-1, keepdims=True))(cbam_feature)\n","\n","    concat = Concatenate()([avg_pool, max_pool])\n","    cbam_feature = Conv3D(filters = 1,kernel_size=kernel_size,strides=1,padding='same',activation='sigmoid',\n","                    kernel_initializer='he_normal',\n","                    use_bias=False)(concat)\t\n","    return Multiply()([input_feature, cbam_feature])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Vf8EL_PzgtlE"},"outputs":[],"source":["class Swish(tf.keras.layers.Layer):\n","    def __init__(self, name=None, **kwargs):\n","        super().__init__(name=name, **kwargs)\n","\n","    def call(self, inputs, **kwargs):\n","        return tf.nn.swish(inputs)\n","    def get_config(self):\n","        config = super().get_config()\n","        config['name'] = self.name\n","        return config\n","def convBn(inputs, filters,kernel_size = (3,3,3), block_size = 1, keep_prob = 1):\n","    x = Conv3D(filters, kernel_size, padding=\"same\", use_bias=False,kernel_initializer='he_normal')(inputs)\n","    x = DropBlock3D(block_size = block_size, keep_prob = keep_prob)(x)\n","    x = BatchNormalization()(x)\n","    x = Swish()(x)\n","    x = cbam_block(x)\n","    return x\n","def downSampleBlock(inputs, block_size = 1, keep_prob = 1 ):\n","    indim = inputs.shape[-1] // 2\n","    x = convBn(inputs, indim, (1,1,1), block_size = block_size, keep_prob = keep_prob)\n","    x = Conv3D(indim, (2,2,2),strides=(2,2,2), padding=\"same\", use_bias=False,kernel_initializer='he_normal')(x)\n","    return x\n","def attention_module(inputs, skip, n_filter):\n","    x = Conv3D(n_filter, (1, 1, 1), padding='same', kernel_initializer='he_normal',use_bias=False)(inputs)\n","    x = BatchNormalization()(x)\n","    x = Conv3DTranspose(n_filter, (2, 2, 2), strides=(2, 2, 2), padding='same',kernel_initializer = 'he_normal')(x)\n","\n","    x1= Conv3D(n_filter, (1, 1, 1), padding='same', kernel_initializer='he_normal',use_bias=False)(skip)\n","    x1 = BatchNormalization()(x1)\n","\n","    out = Swish()(x1+x)\n","    out = cbam_block(out)\n","    out = Conv3D(1, (1, 1, 1), padding='same', kernel_initializer='he_normal',use_bias=False)(out)\n","    out = BatchNormalization()(out)\n","    out = Activation('sigmoid')(out)\n","    skip = Multiply()([out, skip])\n","    skip = cbam_block(skip)\n","    return skip\n","def ResidualBlock(inputs, block_size = 1, keep_prob = 1):\n","    indim = inputs.shape[-1]\n","    residual = convBn(inputs, indim, kernel_size=(1,1,1), block_size = block_size, keep_prob = keep_prob)\n","    residual = convBn(residual, indim // 2 , block_size = block_size, keep_prob = keep_prob)\n","    residual = convBn(residual, indim, kernel_size=(1,1,1), block_size = block_size, keep_prob = keep_prob)\n","    \n","    return Add()([inputs, residual])\n","def decoder_block(inputs, n_filter, skip=None, block_size = 1, keep_prob = 1, types = \"encoder\"):\n","    x= Conv3DTranspose(n_filter, (2,2,2), strides=(2, 2, 2), padding='same',kernel_initializer = 'he_normal')(inputs)\n","    out = x\n","    if skip is not None :\n","        attention = attention_module(inputs,skip, n_filter)\n","        out = Concatenate()([x,attention])\n","    if  types == \"encoder\":\n","        out = convBn(out, n_filter, block_size = block_size, keep_prob = keep_prob)\n","    else: \n","        out = ResidualBlock(out, block_size = block_size, keep_prob = keep_prob)\n","    return out"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"U4jC972Y5fv4"},"outputs":[],"source":["def RSU4times(input_feature, mid_ch = 16, out_ch = 64, keep_prob = 1):\n","    residual = convBn(input_feature, out_ch, block_size=7, keep_prob=keep_prob)\n","\n","    skip1 = convBn(residual, mid_ch, block_size=7, keep_prob=keep_prob)\n","    output = downSampleBlock(skip1, block_size = 7, keep_prob = keep_prob)\n","\n","    skip2 = convBn(output, mid_ch, block_size= 5, keep_prob=keep_prob)\n","    output = downSampleBlock(skip2,block_size = 5, keep_prob = keep_prob)\n","\n","    skip3 = convBn(output, mid_ch, block_size=3, keep_prob=keep_prob )\n","    output = downSampleBlock(skip3, block_size = 3, keep_prob = keep_prob)\n","\n","    skip4 = convBn(output, mid_ch, block_size= 2, keep_prob=keep_prob)\n","    output = downSampleBlock(skip4, block_size = 2, keep_prob = keep_prob)\n","\n","    output = convBn(output, mid_ch, keep_prob= keep_prob)\n","    output = convBn(output, mid_ch, (1,1,1), keep_prob= keep_prob)\n","    \n","    skip_connects = [skip4, skip3, skip2, skip1]\n","    blockSizes = [2, 3, 5, 7]\n","    for i in range(4):\n","        filters = mid_ch if i < 3 else out_ch\n","        output = decoder_block(output, filters ,skip=skip_connects[i],\n","                               block_size = blockSizes[i], keep_prob=keep_prob)\n","    return Add()([output, residual])\n","\n","def RSU3times(input_feature, mid_ch = 16, out_ch = 64, keep_prob = 1):\n","    residual = convBn(input_feature, out_ch, block_size=5, keep_prob=keep_prob)\n","\n","    skip1 = convBn(residual, mid_ch, block_size=5, keep_prob=keep_prob)\n","    output = downSampleBlock(skip1, block_size = 5, keep_prob = keep_prob)\n","\n","    skip2 = convBn(output, mid_ch, block_size=3, keep_prob=keep_prob)\n","    output = downSampleBlock(skip2,block_size = 3, keep_prob = keep_prob)\n","\n","    skip3 = convBn(output, mid_ch, block_size=2, keep_prob=keep_prob )\n","    output = downSampleBlock(skip3, block_size = 2, keep_prob = keep_prob)\n","\n","    output = convBn(output, mid_ch, keep_prob= keep_prob)\n","    output = convBn(output, mid_ch, (1,1,1), keep_prob= keep_prob)\n","    \n","    skip_connects = [skip3, skip2, skip1]\n","    blockSizes = [2, 3, 5]\n","    for i in range(3):\n","        filters = mid_ch if i < 2 else out_ch\n","        output = decoder_block(output, filters ,skip=skip_connects[i],\n","                               block_size = blockSizes[i], keep_prob=keep_prob)\n","    return Add()([output, residual])\n","\n","def RSU2times(input_feature, mid_ch = 16, out_ch = 64, keep_prob = 1):\n","    residual = convBn(input_feature, out_ch, block_size=3, keep_prob=keep_prob)\n","\n","    skip1 = convBn(residual, mid_ch, block_size=3, keep_prob=keep_prob)\n","    output = downSampleBlock(skip1, block_size = 3, keep_prob = keep_prob)\n","\n","    skip2 = convBn(output, mid_ch, block_size=2, keep_prob=keep_prob)\n","    output = downSampleBlock(skip2,block_size = 2, keep_prob = keep_prob)\n","\n","    output = convBn(output, mid_ch, keep_prob= keep_prob)\n","    output = convBn(output, mid_ch, (1,1,1), keep_prob= keep_prob)\n","    \n","    skip_connects = [skip2, skip1]\n","    blockSizes = [2, 3]\n","    for i in range(2):\n","        filters = mid_ch if i < 1 else out_ch\n","        output = decoder_block(output, filters ,skip=skip_connects[i],\n","                               block_size = blockSizes[i], keep_prob=keep_prob)\n","    return Add()([output, residual])\n","\n","def RSU1times(input_feature, mid_ch = 16, out_ch = 64, keep_prob = 1):\n","    residual = convBn(input_feature, out_ch, block_size=2, keep_prob=keep_prob)\n","\n","    skip1 = convBn(residual, mid_ch, block_size=2, keep_prob=keep_prob)\n","    output = downSampleBlock(skip1, block_size = 2, keep_prob = keep_prob)\n","\n","    output = convBn(output, mid_ch, keep_prob= keep_prob)\n","    output = convBn(output, mid_ch, (1,1,1), keep_prob= keep_prob)\n","    \n","    output = decoder_block(output, out_ch ,skip=skip1,\n","                        block_size = 2, keep_prob=keep_prob)\n","    return Add()([output, residual])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hzH6IMOlCw3p"},"outputs":[],"source":["def seg_net(input_shape= (32,32,32,1), out_channels = 4, keep_prob = 1):\n","    inputT1 = Input(shape=input_shape, name=\"inputT1\")\n","    inputT2 = Input(shape=input_shape, name=\"inputT2\")\n","\n","    outputT1 = convBn(inputT1, 16)\n","    outputT2 = convBn(inputT2, 16)\n","    output = Concatenate()([outputT1, outputT2])\n","    output = convBn(output, 32)\n","\n","    skip1 = RSU4times(output, mid_ch = 16, out_ch = 64, keep_prob = keep_prob)\n","    output = downSampleBlock(skip1, block_size = 7, keep_prob = keep_prob)\n","\n","    skip2 = RSU3times(output, mid_ch = 32, out_ch = 64, keep_prob = keep_prob)\n","    output = downSampleBlock(skip2, block_size = 5, keep_prob = keep_prob)\n","\n","    skip3 = RSU2times(output, mid_ch = 32, out_ch = 128, keep_prob = keep_prob)\n","    output = downSampleBlock(skip3, block_size = 3, keep_prob = keep_prob)\n","\n","    skip4 = RSU1times(output, mid_ch = 64, out_ch = 128, keep_prob = keep_prob)\n","    output = downSampleBlock(skip4, block_size = 2, keep_prob = keep_prob)\n","\n","    output = convBn(output, 256, keep_prob= keep_prob)\n","    output = convBn(output, 256, (1,1,1), keep_prob= keep_prob)\n","\n","    num_filters = [128, 64, 64, 32]\n","    skip_connects = [skip4, skip3, skip2, skip1]\n","    blockSizes = [2, 3, 5, 7]\n","    for i in range(4):\n","        output = decoder_block(output, num_filters[i] ,skip=skip_connects[i],\n","                               block_size = blockSizes[i], keep_prob=keep_prob)\n","\n","    output = Conv3D(out_channels,(1, 1 ,1), kernel_initializer='he_normal')(output)\n","    if out_channels > 1 : \n","        output1 = Activation('softmax', name = \"active\")(output)\n","        output2 = Activation('softmax', name = \"levelset\")(output)\n","    else :\n","        output1 = Activation('sigmoid', name = \"active\")(output)\n","        output2 = Activation('sigmoid', name = \"levelset\")(output)\n","    return Model([inputT1, inputT2], [output1, output2])\n","    # return Model(inp, output)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Sn-2Isg2DDFZ"},"outputs":[],"source":["# S=seg_net(keep_prob=1)\n","# S.summary()"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyO0wd5xwEEy4VfjRhN5OKXx","collapsed_sections":[],"name":"U_Unet.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3.7.13 ('stable_env')","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.7.13"},"vscode":{"interpreter":{"hash":"f4c44228236846489b48d7ca3d9c352a36fad9df41b333a127a7d80da5b1990b"}}},"nbformat":4,"nbformat_minor":0}
